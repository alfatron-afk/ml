import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Load datasets (replace the paths with your local paths)
boston_df = pd.read_csv("/content/drive/MyDrive/HousingData.csv")
auto_mpg_df = pd.read_csv("/content/drive/MyDrive/auto-mpg.csv")

# --- Step 1: Data Preprocessing ---
# Handle NaN values and remove rows with NaN values for Boston Housing
boston_df = boston_df.dropna()

# For Auto MPG, replace '?' with NaN and then drop rows with NaN
# The 'horsepower' column is known to contain '?'
auto_mpg_df['horsepower'] = auto_mpg_df['horsepower'].replace('?', np.nan)
# Convert the 'horsepower' column to numeric type
auto_mpg_df['horsepower'] = pd.to_numeric(auto_mpg_df['horsepower'])
# Now drop rows with NaN, including those where '?' was replaced
auto_mpg_df = auto_mpg_df.dropna()


# --- Step 2: Linear Regression on Boston Housing Dataset ---
# Features and target variable for Boston Housing dataset
X_boston = boston_df[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',
'PTRATIO', 'B', 'LSTAT']]
y_boston = boston_df['MEDV']

# Split the data into training and testing sets
X_train_boston, X_test_boston, y_train_boston, y_test_boston = train_test_split(X_boston, y_boston,
test_size=0.2, random_state=42)

# Linear Regression Model
lin_reg_boston = LinearRegression()
lin_reg_boston.fit(X_train_boston, y_train_boston)

# Predictions on the test set
y_pred_boston = lin_reg_boston.predict(X_test_boston)

# Calculate Mean Squared Error
mse_boston = mean_squared_error(y_test_boston, y_pred_boston)
print(f"Linear Regression MSE on Boston Housing Dataset: {mse_boston}")

# Plot Actual vs Predicted for Boston Housing
plt.figure(figsize=(8, 6))
plt.scatter(y_test_boston, y_pred_boston)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Linear Regression: Actual vs Predicted (Boston Housing)')
plt.show()

# --- Step 3: Polynomial Regression on Auto MPG Dataset ---
# Features and target variable for Auto MPG dataset
# Ensure 'horsepower' is now numeric after handling '?'
X_auto_mpg = auto_mpg_df[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year']]
y_auto_mpg = auto_mpg_df['mpg']

# Split the data into training and testing sets
X_train_auto_mpg, X_test_auto_mpg, y_train_auto_mpg, y_test_auto_mpg = train_test_split(X_auto_mpg, y_auto_mpg, test_size=0.2, random_state=42)

# Apply Polynomial Features (degree 2 for this example)
poly = PolynomialFeatures(degree=2)
X_train_poly= poly.fit_transform(X_train_auto_mpg)
X_test_poly = poly.transform(X_test_auto_mpg)

# Polynomial Regression Model
poly_reg = LinearRegression()
poly_reg.fit(X_train_poly, y_train_auto_mpg)

# Predictions on the test set
y_pred_auto_mpg = poly_reg.predict(X_test_poly)

# Calculate Mean Squared Error
mse_auto_mpg = mean_squared_error(y_test_auto_mpg, y_pred_auto_mpg)
print(f"Polynomial Regression MSE on Auto MPG Dataset: {mse_auto_mpg}")

# Plot Actual vs Predicted for Auto MPG
plt.figure(figsize=(8, 6))
plt.scatter(y_test_auto_mpg, y_pred_auto_mpg)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Polynomial Regression: Actual vs Predicted (Auto MPG)')
plt.show()
